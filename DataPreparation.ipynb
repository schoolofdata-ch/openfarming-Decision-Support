{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data to be Analyzed with Modulos AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For all of these operations to work, we are relying on the data being sorted, as it's done in the notebook DataCleaning.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import display\n",
    "import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib\n",
    "pd.options.display.max_columns = None\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure path variables and number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the cleaned data is stored\n",
    "fpath_clean_data_dir = 'clean_data/'\n",
    "\n",
    "# Path where the data ready for the ML analysis is stored and filename of output file\n",
    "fpath_prepared_data_dir = 'ready_data/'\n",
    "foldername_prepared_data = 'ai_basic_all/'\n",
    "\n",
    "# Number of unique Cow IDs to consider (the computation is very slow\n",
    "# Including all samples is only advised once one is happy with the sample)\n",
    "nsamples = None  # Full length for nsamples = None\n",
    "# nsamples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {fpath_prepared_data_dir}{foldername_prepared_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_cow_by_id(df, cow_id, id_label='idani_anon'):\n",
    "    \"\"\"\n",
    "    Function to return all the entries matching a specific cow ID.\n",
    "    \n",
    "    :param df: Pandas dataframe\n",
    "    :param cow_id: Specific cow ID to select\n",
    "    :return: Entries for the corresponding cow ID\n",
    "    \"\"\"\n",
    "    return df[df[id_label]==cow_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all relevant tables into one dictionary. Note that we are not considering hm_BCS and hm_pregnancy in this first implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File names all: ['hm_lactation', 'hm_NSAIET', 'hm_animal', 'hm_milkrecording', 'hm_ebv', 'hm_health']\n"
     ]
    }
   ],
   "source": [
    "# Columns with datetime entries & file names\n",
    "datetime_cols = {#'hm_BCS': ['BCS_date'],\n",
    "                 'hm_lactation': ['calving_date'],\n",
    "                 'hm_NSAIET': ['nsaiet_date'],\n",
    "                 'hm_animal': ['birth_date'], \n",
    "                 'hm_milkrecording': ['mlksmpl_date', 'lab_date'],\n",
    "                 'hm_ebv': False,\n",
    "#                  'hm_pregnancy': ['pregnancy_detection_date'],\n",
    "                 'hm_health': ['healthevent_date']\n",
    "                 }\n",
    "\n",
    "fnames = list(datetime_cols.keys())\n",
    "print('File names all:', fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Reading in hm_lactation.csv -----\n",
      "   parity calving_date calving_ease       idani_anon\n",
      "0       1   2018-09-06            2  CHE000000000561\n",
      "1       2   2019-09-15            2  CHE000000000561\n",
      "2       1   2016-09-07            2  CHE000000000781\n",
      "3       2   2017-08-05            1  CHE000000000781\n",
      "4       3   2018-10-18          2.5  CHE000000000781\n",
      "5       4   2019-09-29            1  CHE000000000781\n",
      "6       1   2017-11-01            1  CHE000000001494\n",
      "7       2   2018-11-01            2  CHE000000001494\n",
      "8       3   2020-01-01            2  CHE000000001494\n",
      "9       1   2013-09-28            1  CHE000000002000\n",
      "\n",
      "----- Reading in hm_NSAIET.csv -----\n",
      "   parity nsaiet_date nsaiet_type  AI_technician       idani_anon  \\\n",
      "0       0  2017-11-05    Besamung             10  CHE000000000561   \n",
      "1       0  2017-11-28    Besamung             10  CHE000000000561   \n",
      "2       1  2018-11-16    Besamung             10  CHE000000000561   \n",
      "3       1  2018-12-05    Besamung             10  CHE000000000561   \n",
      "4       2  2019-12-09    Besamung             10  CHE000000000561   \n",
      "5       2  2019-12-10    Besamung             10  CHE000000000561   \n",
      "6       2  2020-01-31    Besamung             10  CHE000000000561   \n",
      "7       0  2015-11-19    Belegung              5  CHE000000000781   \n",
      "8       1  2016-10-22    Besamung             10  CHE000000000781   \n",
      "9       2  2017-11-05    Besamung             10  CHE000000000781   \n",
      "\n",
      "  idani_anon_aisire  \n",
      "0   CHE000020282537  \n",
      "1   CHE000020282537  \n",
      "2   CHE000002123235  \n",
      "3   CHE000002123235  \n",
      "4   CHE000001110094  \n",
      "5   CHE000001110094  \n",
      "6   CHE000090893216  \n",
      "7   CHE000018236237  \n",
      "8   CHE000064498506  \n",
      "9   CHE000076479306  \n",
      "\n",
      "----- Reading in hm_animal.csv -----\n",
      "  birth_date brd_abbr_icar       idani_anon\n",
      "0 2016-03-08           HOL  CHE000000000559\n",
      "1 2016-02-27           HOL  CHE000000000561\n",
      "2 2011-05-09           HOL  CHE000000000620\n",
      "3 2014-06-23           HOL  CHE000000000781\n",
      "4 2015-11-25           HOL  CHE000000001494\n",
      "5 2018-04-09           HOL  CHE000000001501\n",
      "6 2011-10-11           HOL  CHE000000002000\n",
      "7 2013-04-21           HOL  CHE000000002068\n",
      "8 2008-07-26           HOL  CHE000000002251\n",
      "9 2010-09-14           HOL  CHE000000002451\n",
      "\n",
      "----- Reading in hm_milkrecording.csv -----\n",
      "  mlksmpl_date  milking_time_morning  milking_time_evening   lab_date    DIM  \\\n",
      "0   2018-10-10               50000.0              163000.0 2018-10-11   34.0   \n",
      "1   2018-11-13               50000.0              163000.0 2018-11-15   68.0   \n",
      "2   2018-12-18               50000.0              163000.0 2018-12-19  103.0   \n",
      "3   2019-01-21               50000.0              163000.0 2019-01-23  137.0   \n",
      "4   2019-02-23               50000.0              163000.0 2019-02-26  170.0   \n",
      "5   2019-03-29               50000.0              163500.0 2019-04-02  204.0   \n",
      "6   2019-05-06               50000.0              163500.0 2019-05-07  242.0   \n",
      "7   2019-06-07               50000.0              163000.0 2019-06-12  274.0   \n",
      "8   2019-07-12               50000.0              163000.0 2019-07-15  309.0   \n",
      "9   2019-09-20               50000.0              163000.0 2019-09-23    5.0   \n",
      "\n",
      "  pruefmethode melkmethode  milk_yield_24h  fat_24h  protein_24h  lactose_24h  \\\n",
      "0          AT4      Normal            34.2     36.5         24.9         49.8   \n",
      "1          AT4      Normal            34.1     34.9         29.2         50.3   \n",
      "2          AT4      Normal            30.9     37.2         26.7         48.3   \n",
      "3          AT4      Normal            36.3     36.8         31.1         50.0   \n",
      "4          AT4      Normal            35.3     34.2         29.6         48.6   \n",
      "5          AT4      Normal            37.0     35.7         31.2         48.8   \n",
      "6          AT4      Normal            34.6     37.0         30.1         48.9   \n",
      "7          AT4      Normal            30.5     39.5         31.2         48.3   \n",
      "8          AT4      Normal            30.9     34.5         29.2         47.8   \n",
      "9          AT4      Normal            40.1     40.2         42.3         47.5   \n",
      "\n",
      "   scc_24h  urea_24h  AR_PESEE_PESCODEALPAGE       idani_anon  \\\n",
      "0     21.0       2.4                     0.0  CHE000000000561   \n",
      "1     80.0       2.2                     0.0  CHE000000000561   \n",
      "2    132.0       1.6                     0.0  CHE000000000561   \n",
      "3    106.0       2.1                     0.0  CHE000000000561   \n",
      "4    133.0       1.5                     0.0  CHE000000000561   \n",
      "5    103.0       2.1                     0.0  CHE000000000561   \n",
      "6     67.0       1.4                     0.0  CHE000000000561   \n",
      "7    129.0       2.4                     0.0  CHE000000000561   \n",
      "8     22.0       2.0                     0.0  CHE000000000561   \n",
      "9     34.0       1.8                     0.0  CHE000000000561   \n",
      "\n",
      "        idhrd_anon  milk_yield_msrmt_type  fat_protein_24h_ratio  \n",
      "0  CHE000000095710                      2               1.465863  \n",
      "1  CHE000000095710                      3               1.195205  \n",
      "2  CHE000000095710                      2               1.393258  \n",
      "3  CHE000000095710                      3               1.183280  \n",
      "4  CHE000000095710                      2               1.155405  \n",
      "5  CHE000000095710                      3               1.144231  \n",
      "6  CHE000000095710                      2               1.229236  \n",
      "7  CHE000000095710                      3               1.266026  \n",
      "8  CHE000000095710                      2               1.181507  \n",
      "9  CHE000000095710                      2               0.950355  \n",
      "\n",
      "----- Reading in hm_ebv.csv -----\n",
      "   base label       idani_anon   ekg   epr   fkg   fpr     mkg   per    scs\n",
      "0  HO20     A  CHE000000000559 -23.0 -0.02 -31.0 -0.07  -636.0  93.0  102.0\n",
      "1  HO20    CH  CHE000000000561  18.0 -0.23  26.0 -0.24  1173.0  93.0   89.0\n",
      "2  HO20     A  CHE000000000620   5.0  0.11  -1.0  0.05  -147.0  99.0   94.0\n",
      "3  HO20    CH  CHE000000000781   0.0 -0.07  -2.0 -0.11   179.0  95.0  106.0\n",
      "4  HO20    CH  CHE000000001494   3.0  0.11  -4.0  0.04  -179.0  93.0  111.0\n",
      "5  HO20     A  CHE000000001501  36.0  0.08  30.0 -0.07   887.0  87.0   99.0\n",
      "6  HO20    CH  CHE000000002000 -14.0  0.04 -17.0  0.05  -514.0  92.0  101.0\n",
      "7  HO20    CH  CHE000000002068 -23.0 -0.06 -23.0 -0.01  -546.0  96.0  110.0\n",
      "8  HO20    CH  CHE000000002251  -2.0 -0.15   7.0 -0.07   328.0  98.0  100.0\n",
      "9  HO20    CH  CHE000000002451 -11.0 -0.06 -30.0 -0.28  -177.0  95.0   94.0\n",
      "\n",
      "----- Reading in hm_health.csv -----\n",
      "  hecode_ASR healthevent_date       idani_anon       idhrd_anon\n",
      "0    10.7.1.       2018-11-19  CHE000000005877  CHE000000079291\n",
      "1     2.1.1.       2018-12-20  CHE000000005877  CHE000000079291\n",
      "2      10.4.       2019-09-06  CHE000000005877  CHE000000079291\n",
      "3       3.5.       2020-03-14  CHE000000005877  CHE000000079291\n",
      "4       6.1.       2014-06-02  CHE000000006772  CHE000000055108\n",
      "5       1.2.       2015-11-30  CHE000000006772  CHE000000055108\n",
      "6     3.3.3.       2018-04-12  CHE000000006772  CHE000000094671\n",
      "7      10.8.       2019-01-22  CHE000000006772  CHE000000055108\n",
      "8      10.4.       2019-01-22  CHE000000006772  CHE000000055108\n",
      "9     2.2.3.       2016-12-29  CHE000000019899  CHE000000006820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frames = {}\n",
    "for fname in fnames:\n",
    "    print('----- Reading in {:}.csv -----'.format(fname))\n",
    "    fpath = fpath_clean_data_dir+fname+'.csv'\n",
    "    data_frames[fname] = pd.read_csv(fpath, parse_dates=datetime_cols[fname])\n",
    "    print(data_frames[fname].head(10))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation & Enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all parity = 0 entries (i.e. inseminations before the cow has even given birth and milk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 329889 entries (24.15%)\n"
     ]
    }
   ],
   "source": [
    "orig_rows = data_frames['hm_NSAIET'].shape[0]\n",
    "mask = np.argwhere(data_frames['hm_NSAIET']['parity'].values == 0).flatten()\n",
    "data_frames['hm_NSAIET'] = data_frames['hm_NSAIET'].drop(mask, axis=0).reset_index(drop=True)\n",
    "print('Removed {:} entries ({:.2f}%)'.format(orig_rows-data_frames['hm_NSAIET'].shape[0],\n",
    "                                             (1-data_frames['hm_NSAIET'].shape[0]/orig_rows)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of unique cow IDs by considering intersection of all the tables with necessary inputs for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individual cows in sample: 180005\n"
     ]
    }
   ],
   "source": [
    "# Tables necessary for the prediction ('hm_health' doesn't contain many cows and\n",
    "# one would have to throw away much data)\n",
    "fnames_necessary = [fname for fname in fnames if fname != 'hm_health']\n",
    "\n",
    "# Select subset\n",
    "unique_cow_ids = [set(data_frames[fname]['idani_anon'].values) for fname in fnames_necessary]\n",
    "unique_cow_ids = list(set.intersection(*unique_cow_ids))\n",
    "\n",
    "print('Number of individual cows in sample: {:}'.format(len(unique_cow_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert parity to labels (= column used for prediction)\n",
    "If the same parity number occurs multiple times only the one with the most recent time stamp is considered a success. The other are considered failures. Parities that only appear once are considered success by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parity_to_label_for_single_cow(df):\n",
    "    \"\"\"\n",
    "    Function to return a new column called 'parity_labels', which contains True/False depending on the\n",
    "    outcome of the artificial insemination.\n",
    "    \n",
    "    :param df: Subset of a Pandas dataframe containing all the relevant entries for a single cow\n",
    "    :return: Column with labels encoding a successful/unsuccessful insemination (1 or 0)\n",
    "    \"\"\"\n",
    "\n",
    "    parity_values = df['parity'].values\n",
    "\n",
    "    parity_labels = []\n",
    "    parity_values_seen = []\n",
    "\n",
    "    for p in parity_values[::-1]:\n",
    "        if not p in parity_values_seen:\n",
    "            parity_labels.append(1)\n",
    "            parity_values_seen.append(p)\n",
    "        else:\n",
    "            parity_labels.append(0)\n",
    "\n",
    "    return parity_labels[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert labels for all cows (using unique_cow_ids from above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180005/180005 [00:33<00:00, 5410.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples removed due to inconsistencies between the parities and the NSAIET-date: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ids_to_remove = 0\n",
    "\n",
    "parity_labels_all = np.zeros(data_frames['hm_NSAIET'].shape[0], dtype=np.int)\n",
    "for cow_id in tqdm.tqdm(unique_cow_ids):\n",
    "    left = data_frames['hm_NSAIET'][\"idani_anon\"].searchsorted(cow_id, 'left')\n",
    "    right = data_frames['hm_NSAIET'][\"idani_anon\"].searchsorted(cow_id, 'right')\n",
    "    \n",
    "    single_cow = data_frames['hm_NSAIET'][left:right]\n",
    "    \n",
    "    parity_values = single_cow['parity'].values\n",
    "    if (parity_values != sorted(parity_values)).all():\n",
    "        unique_cow_ids.remove(cow_id)\n",
    "        ids_to_remove += 1\n",
    "        \n",
    "    else:\n",
    "        parity_labels_all[left:right] = parity_to_label_for_single_cow(single_cow)\n",
    "        \n",
    "data_frames['hm_NSAIET']['parity_labels'] = parity_labels_all\n",
    "\n",
    "print('Samples removed due to inconsistencies between the parities and the NSAIET-date: {:}'.format(ids_to_remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display all dataframes individually (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parity</th>\n",
       "      <th>calving_date</th>\n",
       "      <th>calving_ease</th>\n",
       "      <th>idani_anon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-06</td>\n",
       "      <td>2</td>\n",
       "      <td>CHE000000000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>2</td>\n",
       "      <td>CHE000000000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>2</td>\n",
       "      <td>CHE000000000781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-08-05</td>\n",
       "      <td>1</td>\n",
       "      <td>CHE000000000781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>2.5</td>\n",
       "      <td>CHE000000000781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637269</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>2</td>\n",
       "      <td>CHE000099999926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637270</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-03-24</td>\n",
       "      <td>1</td>\n",
       "      <td>CHE000099999926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637271</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-03-05</td>\n",
       "      <td>2</td>\n",
       "      <td>CHE000099999926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637272</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>3</td>\n",
       "      <td>CHE000099999926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637273</th>\n",
       "      <td>5</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>2</td>\n",
       "      <td>CHE000099999926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637274 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        parity calving_date calving_ease       idani_anon\n",
       "0            1   2018-09-06            2  CHE000000000561\n",
       "1            2   2019-09-15            2  CHE000000000561\n",
       "2            1   2016-09-07            2  CHE000000000781\n",
       "3            2   2017-08-05            1  CHE000000000781\n",
       "4            3   2018-10-18          2.5  CHE000000000781\n",
       "...        ...          ...          ...              ...\n",
       "637269       1   2013-02-26            2  CHE000099999926\n",
       "637270       2   2014-03-24            1  CHE000099999926\n",
       "637271       3   2015-03-05            2  CHE000099999926\n",
       "637272       4   2016-06-18            3  CHE000099999926\n",
       "637273       5   2017-11-14            2  CHE000099999926\n",
       "\n",
       "[637274 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames['hm_lactation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parity</th>\n",
       "      <th>nsaiet_date</th>\n",
       "      <th>nsaiet_type</th>\n",
       "      <th>AI_technician</th>\n",
       "      <th>idani_anon</th>\n",
       "      <th>idani_anon_aisire</th>\n",
       "      <th>parity_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-16</td>\n",
       "      <td>Besamung</td>\n",
       "      <td>10</td>\n",
       "      <td>CHE000000000561</td>\n",
       "      <td>CHE000002123235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-05</td>\n",
       "      <td>Besamung</td>\n",
       "      <td>10</td>\n",
       "      <td>CHE000000000561</td>\n",
       "      <td>CHE000002123235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-09</td>\n",
       "      <td>Besamung</td>\n",
       "      <td>10</td>\n",
       "      <td>CHE000000000561</td>\n",
       "      <td>CHE000001110094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>Besamung</td>\n",
       "      <td>10</td>\n",
       "      <td>CHE000000000561</td>\n",
       "      <td>CHE000001110094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>Besamung</td>\n",
       "      <td>10</td>\n",
       "      <td>CHE000000000561</td>\n",
       "      <td>CHE000090893216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036244</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-06-13</td>\n",
       "      <td>Besamung</td>\n",
       "      <td>10</td>\n",
       "      <td>CHE000099999926</td>\n",
       "      <td>CHE000025255973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036245</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-05-19</td>\n",
       "      <td>Besamung</td>\n",
       "      <td>10</td>\n",
       "      <td>CHE000099999926</td>\n",
       "      <td>CHE000038915903</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036246</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-09-02</td>\n",
       "      <td>Belegung</td>\n",
       "      <td>5</td>\n",
       "      <td>CHE000099999926</td>\n",
       "      <td>CHE000099239508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036247</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>Besamung</td>\n",
       "      <td>10</td>\n",
       "      <td>CHE000099999926</td>\n",
       "      <td>CHE000045797183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036248</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>Besamung</td>\n",
       "      <td>10</td>\n",
       "      <td>CHE000099999926</td>\n",
       "      <td>CHE000079801145</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036249 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         parity nsaiet_date nsaiet_type  AI_technician       idani_anon  \\\n",
       "0             1  2018-11-16    Besamung             10  CHE000000000561   \n",
       "1             1  2018-12-05    Besamung             10  CHE000000000561   \n",
       "2             2  2019-12-09    Besamung             10  CHE000000000561   \n",
       "3             2  2019-12-10    Besamung             10  CHE000000000561   \n",
       "4             2  2020-01-31    Besamung             10  CHE000000000561   \n",
       "...         ...         ...         ...            ...              ...   \n",
       "1036244       1  2013-06-13    Besamung             10  CHE000099999926   \n",
       "1036245       2  2014-05-19    Besamung             10  CHE000099999926   \n",
       "1036246       3  2015-09-02    Belegung              5  CHE000099999926   \n",
       "1036247       4  2016-10-14    Besamung             10  CHE000099999926   \n",
       "1036248       4  2017-01-24    Besamung             10  CHE000099999926   \n",
       "\n",
       "        idani_anon_aisire  parity_labels  \n",
       "0         CHE000002123235              0  \n",
       "1         CHE000002123235              1  \n",
       "2         CHE000001110094              0  \n",
       "3         CHE000001110094              0  \n",
       "4         CHE000090893216              1  \n",
       "...                   ...            ...  \n",
       "1036244   CHE000025255973              1  \n",
       "1036245   CHE000038915903              1  \n",
       "1036246   CHE000099239508              1  \n",
       "1036247   CHE000045797183              0  \n",
       "1036248   CHE000079801145              1  \n",
       "\n",
       "[1036249 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames['hm_NSAIET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birth_date</th>\n",
       "      <th>brd_abbr_icar</th>\n",
       "      <th>idani_anon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-08</td>\n",
       "      <td>HOL</td>\n",
       "      <td>CHE000000000559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-27</td>\n",
       "      <td>HOL</td>\n",
       "      <td>CHE000000000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-05-09</td>\n",
       "      <td>HOL</td>\n",
       "      <td>CHE000000000620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-06-23</td>\n",
       "      <td>HOL</td>\n",
       "      <td>CHE000000000781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-25</td>\n",
       "      <td>HOL</td>\n",
       "      <td>CHE000000001494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275766</th>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>HOL</td>\n",
       "      <td>CHE000099998134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275767</th>\n",
       "      <td>2016-11-28</td>\n",
       "      <td>HOL</td>\n",
       "      <td>CHE000099998152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275768</th>\n",
       "      <td>2013-11-12</td>\n",
       "      <td>HOL</td>\n",
       "      <td>CHE000099998376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275769</th>\n",
       "      <td>2015-09-07</td>\n",
       "      <td>HOL</td>\n",
       "      <td>CHE000099999361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275770</th>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>HOL</td>\n",
       "      <td>CHE000099999926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275771 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       birth_date brd_abbr_icar       idani_anon\n",
       "0      2016-03-08           HOL  CHE000000000559\n",
       "1      2016-02-27           HOL  CHE000000000561\n",
       "2      2011-05-09           HOL  CHE000000000620\n",
       "3      2014-06-23           HOL  CHE000000000781\n",
       "4      2015-11-25           HOL  CHE000000001494\n",
       "...           ...           ...              ...\n",
       "275766 2014-01-06           HOL  CHE000099998134\n",
       "275767 2016-11-28           HOL  CHE000099998152\n",
       "275768 2013-11-12           HOL  CHE000099998376\n",
       "275769 2015-09-07           HOL  CHE000099999361\n",
       "275770 2011-01-26           HOL  CHE000099999926\n",
       "\n",
       "[275771 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames['hm_animal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mlksmpl_date</th>\n",
       "      <th>milking_time_morning</th>\n",
       "      <th>milking_time_evening</th>\n",
       "      <th>lab_date</th>\n",
       "      <th>DIM</th>\n",
       "      <th>pruefmethode</th>\n",
       "      <th>melkmethode</th>\n",
       "      <th>milk_yield_24h</th>\n",
       "      <th>fat_24h</th>\n",
       "      <th>protein_24h</th>\n",
       "      <th>lactose_24h</th>\n",
       "      <th>scc_24h</th>\n",
       "      <th>urea_24h</th>\n",
       "      <th>AR_PESEE_PESCODEALPAGE</th>\n",
       "      <th>idani_anon</th>\n",
       "      <th>idhrd_anon</th>\n",
       "      <th>milk_yield_msrmt_type</th>\n",
       "      <th>fat_protein_24h_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>163000.0</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>34.0</td>\n",
       "      <td>AT4</td>\n",
       "      <td>Normal</td>\n",
       "      <td>34.2</td>\n",
       "      <td>36.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>49.8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHE000000000561</td>\n",
       "      <td>CHE000000095710</td>\n",
       "      <td>2</td>\n",
       "      <td>1.465863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-13</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>163000.0</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AT4</td>\n",
       "      <td>Normal</td>\n",
       "      <td>34.1</td>\n",
       "      <td>34.9</td>\n",
       "      <td>29.2</td>\n",
       "      <td>50.3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHE000000000561</td>\n",
       "      <td>CHE000000095710</td>\n",
       "      <td>3</td>\n",
       "      <td>1.195205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>163000.0</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>103.0</td>\n",
       "      <td>AT4</td>\n",
       "      <td>Normal</td>\n",
       "      <td>30.9</td>\n",
       "      <td>37.2</td>\n",
       "      <td>26.7</td>\n",
       "      <td>48.3</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHE000000000561</td>\n",
       "      <td>CHE000000095710</td>\n",
       "      <td>2</td>\n",
       "      <td>1.393258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>163000.0</td>\n",
       "      <td>2019-01-23</td>\n",
       "      <td>137.0</td>\n",
       "      <td>AT4</td>\n",
       "      <td>Normal</td>\n",
       "      <td>36.3</td>\n",
       "      <td>36.8</td>\n",
       "      <td>31.1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHE000000000561</td>\n",
       "      <td>CHE000000095710</td>\n",
       "      <td>3</td>\n",
       "      <td>1.183280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-23</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>163000.0</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>170.0</td>\n",
       "      <td>AT4</td>\n",
       "      <td>Normal</td>\n",
       "      <td>35.3</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.6</td>\n",
       "      <td>48.6</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHE000000000561</td>\n",
       "      <td>CHE000000095710</td>\n",
       "      <td>2</td>\n",
       "      <td>1.155405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116724</th>\n",
       "      <td>2018-08-06</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>172000.0</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>265.0</td>\n",
       "      <td>AT4</td>\n",
       "      <td>Normal</td>\n",
       "      <td>27.9</td>\n",
       "      <td>43.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>44.1</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHE000099999926</td>\n",
       "      <td>CHE000000031281</td>\n",
       "      <td>2</td>\n",
       "      <td>1.330275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116725</th>\n",
       "      <td>2018-09-07</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>2018-09-10</td>\n",
       "      <td>297.0</td>\n",
       "      <td>AT4</td>\n",
       "      <td>Normal</td>\n",
       "      <td>30.7</td>\n",
       "      <td>58.8</td>\n",
       "      <td>38.4</td>\n",
       "      <td>44.6</td>\n",
       "      <td>517.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHE000099999926</td>\n",
       "      <td>CHE000000031281</td>\n",
       "      <td>3</td>\n",
       "      <td>1.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116726</th>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>330.0</td>\n",
       "      <td>AT4</td>\n",
       "      <td>Normal</td>\n",
       "      <td>25.3</td>\n",
       "      <td>52.2</td>\n",
       "      <td>40.6</td>\n",
       "      <td>43.5</td>\n",
       "      <td>235.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHE000099999926</td>\n",
       "      <td>CHE000000031281</td>\n",
       "      <td>2</td>\n",
       "      <td>1.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116727</th>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>2018-11-14</td>\n",
       "      <td>363.0</td>\n",
       "      <td>AT4</td>\n",
       "      <td>Normal</td>\n",
       "      <td>19.8</td>\n",
       "      <td>52.8</td>\n",
       "      <td>43.3</td>\n",
       "      <td>43.6</td>\n",
       "      <td>166.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHE000099999926</td>\n",
       "      <td>CHE000000031281</td>\n",
       "      <td>3</td>\n",
       "      <td>1.219400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116728</th>\n",
       "      <td>2018-12-14</td>\n",
       "      <td>53500.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>395.0</td>\n",
       "      <td>AT4</td>\n",
       "      <td>Normal</td>\n",
       "      <td>14.7</td>\n",
       "      <td>53.6</td>\n",
       "      <td>43.6</td>\n",
       "      <td>41.7</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CHE000099999926</td>\n",
       "      <td>CHE000000031281</td>\n",
       "      <td>2</td>\n",
       "      <td>1.229358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5116729 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mlksmpl_date  milking_time_morning  milking_time_evening   lab_date  \\\n",
       "0         2018-10-10               50000.0              163000.0 2018-10-11   \n",
       "1         2018-11-13               50000.0              163000.0 2018-11-15   \n",
       "2         2018-12-18               50000.0              163000.0 2018-12-19   \n",
       "3         2019-01-21               50000.0              163000.0 2019-01-23   \n",
       "4         2019-02-23               50000.0              163000.0 2019-02-26   \n",
       "...              ...                   ...                   ...        ...   \n",
       "5116724   2018-08-06               55000.0              172000.0 2018-08-08   \n",
       "5116725   2018-09-07               55000.0              171000.0 2018-09-10   \n",
       "5116726   2018-10-10               53000.0              171000.0 2018-10-11   \n",
       "5116727   2018-11-12               53000.0              165000.0 2018-11-14   \n",
       "5116728   2018-12-14               53500.0              165000.0 2018-12-17   \n",
       "\n",
       "           DIM pruefmethode melkmethode  milk_yield_24h  fat_24h  protein_24h  \\\n",
       "0         34.0          AT4      Normal            34.2     36.5         24.9   \n",
       "1         68.0          AT4      Normal            34.1     34.9         29.2   \n",
       "2        103.0          AT4      Normal            30.9     37.2         26.7   \n",
       "3        137.0          AT4      Normal            36.3     36.8         31.1   \n",
       "4        170.0          AT4      Normal            35.3     34.2         29.6   \n",
       "...        ...          ...         ...             ...      ...          ...   \n",
       "5116724  265.0          AT4      Normal            27.9     43.5         32.7   \n",
       "5116725  297.0          AT4      Normal            30.7     58.8         38.4   \n",
       "5116726  330.0          AT4      Normal            25.3     52.2         40.6   \n",
       "5116727  363.0          AT4      Normal            19.8     52.8         43.3   \n",
       "5116728  395.0          AT4      Normal            14.7     53.6         43.6   \n",
       "\n",
       "         lactose_24h  scc_24h  urea_24h  AR_PESEE_PESCODEALPAGE  \\\n",
       "0               49.8     21.0       2.4                     0.0   \n",
       "1               50.3     80.0       2.2                     0.0   \n",
       "2               48.3    132.0       1.6                     0.0   \n",
       "3               50.0    106.0       2.1                     0.0   \n",
       "4               48.6    133.0       1.5                     0.0   \n",
       "...              ...      ...       ...                     ...   \n",
       "5116724         44.1   1004.0       3.3                     0.0   \n",
       "5116725         44.6    517.0       3.2                     0.0   \n",
       "5116726         43.5    235.0       2.9                     0.0   \n",
       "5116727         43.6    166.0       3.2                     0.0   \n",
       "5116728         41.7    163.0       2.9                     0.0   \n",
       "\n",
       "              idani_anon       idhrd_anon  milk_yield_msrmt_type  \\\n",
       "0        CHE000000000561  CHE000000095710                      2   \n",
       "1        CHE000000000561  CHE000000095710                      3   \n",
       "2        CHE000000000561  CHE000000095710                      2   \n",
       "3        CHE000000000561  CHE000000095710                      3   \n",
       "4        CHE000000000561  CHE000000095710                      2   \n",
       "...                  ...              ...                    ...   \n",
       "5116724  CHE000099999926  CHE000000031281                      2   \n",
       "5116725  CHE000099999926  CHE000000031281                      3   \n",
       "5116726  CHE000099999926  CHE000000031281                      2   \n",
       "5116727  CHE000099999926  CHE000000031281                      3   \n",
       "5116728  CHE000099999926  CHE000000031281                      2   \n",
       "\n",
       "         fat_protein_24h_ratio  \n",
       "0                     1.465863  \n",
       "1                     1.195205  \n",
       "2                     1.393258  \n",
       "3                     1.183280  \n",
       "4                     1.155405  \n",
       "...                        ...  \n",
       "5116724               1.330275  \n",
       "5116725               1.531250  \n",
       "5116726               1.285714  \n",
       "5116727               1.219400  \n",
       "5116728               1.229358  \n",
       "\n",
       "[5116729 rows x 18 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames['hm_milkrecording']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th>label</th>\n",
       "      <th>idani_anon</th>\n",
       "      <th>ekg</th>\n",
       "      <th>epr</th>\n",
       "      <th>fkg</th>\n",
       "      <th>fpr</th>\n",
       "      <th>mkg</th>\n",
       "      <th>per</th>\n",
       "      <th>scs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HO20</td>\n",
       "      <td>A</td>\n",
       "      <td>CHE000000000559</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-636.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HO20</td>\n",
       "      <td>CH</td>\n",
       "      <td>CHE000000000561</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HO20</td>\n",
       "      <td>A</td>\n",
       "      <td>CHE000000000620</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-147.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HO20</td>\n",
       "      <td>CH</td>\n",
       "      <td>CHE000000000781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>179.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HO20</td>\n",
       "      <td>CH</td>\n",
       "      <td>CHE000000001494</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-179.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271769</th>\n",
       "      <td>HO20</td>\n",
       "      <td>CH</td>\n",
       "      <td>CHE000099998134</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271770</th>\n",
       "      <td>HO20</td>\n",
       "      <td>CH</td>\n",
       "      <td>CHE000099998152</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>311.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271771</th>\n",
       "      <td>HO20</td>\n",
       "      <td>CH</td>\n",
       "      <td>CHE000099998376</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-167.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271772</th>\n",
       "      <td>HO20</td>\n",
       "      <td>CH</td>\n",
       "      <td>CHE000099999361</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>365.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271773</th>\n",
       "      <td>HO20</td>\n",
       "      <td>CH</td>\n",
       "      <td>CHE000099999926</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271774 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        base label       idani_anon   ekg   epr   fkg   fpr     mkg    per  \\\n",
       "0       HO20     A  CHE000000000559 -23.0 -0.02 -31.0 -0.07  -636.0   93.0   \n",
       "1       HO20    CH  CHE000000000561  18.0 -0.23  26.0 -0.24  1173.0   93.0   \n",
       "2       HO20     A  CHE000000000620   5.0  0.11  -1.0  0.05  -147.0   99.0   \n",
       "3       HO20    CH  CHE000000000781   0.0 -0.07  -2.0 -0.11   179.0   95.0   \n",
       "4       HO20    CH  CHE000000001494   3.0  0.11  -4.0  0.04  -179.0   93.0   \n",
       "...      ...   ...              ...   ...   ...   ...   ...     ...    ...   \n",
       "271769  HO20    CH  CHE000099998134   6.0  0.11  18.0  0.26   -82.0   89.0   \n",
       "271770  HO20    CH  CHE000099998152   8.0 -0.03   3.0 -0.11   311.0   89.0   \n",
       "271771  HO20    CH  CHE000099998376   8.0  0.16  46.0  0.64  -167.0  104.0   \n",
       "271772  HO20    CH  CHE000099999361  10.0 -0.02  12.0 -0.03   365.0  103.0   \n",
       "271773  HO20    CH  CHE000099999926  -1.0 -0.01  11.0  0.13    -3.0   94.0   \n",
       "\n",
       "          scs  \n",
       "0       102.0  \n",
       "1        89.0  \n",
       "2        94.0  \n",
       "3       106.0  \n",
       "4       111.0  \n",
       "...       ...  \n",
       "271769   90.0  \n",
       "271770  110.0  \n",
       "271771   99.0  \n",
       "271772  111.0  \n",
       "271773   98.0  \n",
       "\n",
       "[271774 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames['hm_ebv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hecode_ASR</th>\n",
       "      <th>healthevent_date</th>\n",
       "      <th>idani_anon</th>\n",
       "      <th>idhrd_anon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.7.1.</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>CHE000000005877</td>\n",
       "      <td>CHE000000079291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1.1.</td>\n",
       "      <td>2018-12-20</td>\n",
       "      <td>CHE000000005877</td>\n",
       "      <td>CHE000000079291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.4.</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>CHE000000005877</td>\n",
       "      <td>CHE000000079291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.5.</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>CHE000000005877</td>\n",
       "      <td>CHE000000079291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.1.</td>\n",
       "      <td>2014-06-02</td>\n",
       "      <td>CHE000000006772</td>\n",
       "      <td>CHE000000055108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53730</th>\n",
       "      <td>2.1.2.</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>CHE000099990201</td>\n",
       "      <td>CHE000000088759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53731</th>\n",
       "      <td>2.5.</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>CHE000099990433</td>\n",
       "      <td>CHE000000059284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53732</th>\n",
       "      <td>2.1.1.</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>CHE000099992995</td>\n",
       "      <td>CHE000000014814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53733</th>\n",
       "      <td>9.3.99.</td>\n",
       "      <td>2013-11-25</td>\n",
       "      <td>CHE000099998376</td>\n",
       "      <td>CHE000000086408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53734</th>\n",
       "      <td>10.2.</td>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>CHE000099998376</td>\n",
       "      <td>CHE000000086408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53735 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hecode_ASR healthevent_date       idani_anon       idhrd_anon\n",
       "0        10.7.1.       2018-11-19  CHE000000005877  CHE000000079291\n",
       "1         2.1.1.       2018-12-20  CHE000000005877  CHE000000079291\n",
       "2          10.4.       2019-09-06  CHE000000005877  CHE000000079291\n",
       "3           3.5.       2020-03-14  CHE000000005877  CHE000000079291\n",
       "4           6.1.       2014-06-02  CHE000000006772  CHE000000055108\n",
       "...          ...              ...              ...              ...\n",
       "53730     2.1.2.       2019-06-15  CHE000099990201  CHE000000088759\n",
       "53731       2.5.       2018-01-30  CHE000099990433  CHE000000059284\n",
       "53732     2.1.1.       2020-03-18  CHE000099992995  CHE000000014814\n",
       "53733    9.3.99.       2013-11-25  CHE000099998376  CHE000000086408\n",
       "53734      10.2.       2013-12-19  CHE000099998376  CHE000000086408\n",
       "\n",
       "[53735 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames['hm_health']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to contain hm_NSAIET with other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_nsaeit_with_milkrecording_single_cow(df_nsaiet, df_milkrec, columns_both='idani_anon'):\n",
    "    \"\"\"\n",
    "    Function combining the dataframes hm_NSAIET and hm_milkrecording for a single cow ID.\n",
    "    The tables are combined such that for every insemination, the date of the previous milkrecording is chosen.\n",
    "    \n",
    "    :param df_nsaiet: Subset of the NSAEIT Pandas dataframe containing the relevant entries for a single cow\n",
    "    :param df_milkrec: Subset of the milkrecording Pandas dataframe containing the relevant entries for a single cow\n",
    "    :param columns_both: Identical columns in both dataframes\n",
    "    :return: Merged dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    combined_df = []\n",
    "    for idx_parity, parity_date in enumerate(df_nsaiet['nsaiet_date'].values):        \n",
    "        # Milk recording dates before the insemination date\n",
    "        indices = np.argwhere((df_milkrec['mlksmpl_date'].values < parity_date)==True).flatten()\n",
    "        \n",
    "        # Throw away values, where there is no milk recording date before the insemination date\n",
    "        if indices.size == 0:\n",
    "            continue\n",
    "            \n",
    "        idx_milkrec = np.argwhere((df_milkrec['mlksmpl_date'].values < parity_date)==True).flatten()[-1]\n",
    "        \n",
    "        # Throw away the value, if the difference between the last milk recording and\n",
    "        # the artificial insemination is longer than 60 days\n",
    "        delta = np.timedelta64(parity_date - df_milkrec['mlksmpl_date'].values[idx_milkrec], 'D') // np.timedelta64(1, 'D')\n",
    "        if delta > 60:\n",
    "            continue\n",
    "        \n",
    "        df = pd.merge(df_nsaiet.iloc[[idx_parity]],\n",
    "                      df_milkrec.iloc[[idx_milkrec]],\n",
    "                      \"inner\", on=columns_both)\n",
    "        combined_df.append(df)\n",
    "    \n",
    "    # Return None for an emtpy dataframe\n",
    "    if len(combined_df) == 0:\n",
    "        return None\n",
    "\n",
    "    return pd.concat(combined_df).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def combine_nsaeit_with_lactation_single_cow(df_nsaiet, df_lactation, columns_both='idani_anon'):\n",
    "    \"\"\"\n",
    "    Function combining the dataframes hm_NSAIET and hm_lactation for a single cow ID.\n",
    "    The tables are combined such that for every insemination, the entry with the same parity is chosen.\n",
    "    \n",
    "    :param df_nsaiet: Subset of the NSAEIT Pandas dataframe containing the relevant entries for a single cow\n",
    "    :param df_lactation: Subset of the lactation Pandas dataframe containing the relevant entries for a single cow\n",
    "    :param columns_both: Identical columns in both dataframes\n",
    "    :return: Merged dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    combined_df = []\n",
    "    for idx_parity, parity in enumerate(df_nsaiet['parity'].values):\n",
    "        idx_lactation = np.argwhere((df_lactation['parity'].values == parity)).flatten()[0]\n",
    "                \n",
    "        df = pd.merge(df_nsaiet.iloc[[idx_parity]],\n",
    "                      df_lactation.iloc[[idx_lactation]],\n",
    "                      \"inner\", on=columns_both)\n",
    "        combined_df.append(df)\n",
    "\n",
    "    return pd.concat(combined_df).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def combine_with_health_single_cow(df_nsaiet, df_health, threshold_health_date=45):\n",
    "    \"\"\"\n",
    "    Add health-events related columns depending on whether there were any recorded health events XX days before the\n",
    "    insemination date.\n",
    "    \n",
    "    :param df_nsaiet: Subset of the NSAEIT Pandas dataframe containing all the relevant entries for a single cow\n",
    "    :param df_other: Subset of the health Pandas dataframe containing all the relevant entries for a single cow\n",
    "    :param threshold_health_date: Number of days before the insemination that a health event is considered to be relevant \n",
    "    :return: Column with number of health events XX days before the artificial insemination\n",
    "    \"\"\"\n",
    "    \n",
    "    healthevents = np.zeros(df_nsaiet.shape[0], dtype=np.float)\n",
    "\n",
    "    if df_health is not None:  \n",
    "        health_dates = df_health['healthevent_date'].values\n",
    "\n",
    "        for idx_parity, parity_date in enumerate(df_nsaiet['nsaiet_date'].values):\n",
    "            deltas = [np.timedelta64(parity_date-date_health, 'D') // np.timedelta64(1, 'D') for date_health in health_dates]\n",
    "            deltas = np.array(deltas, dtype=np.float)\n",
    "            healthevents[idx_parity] = np.sum((deltas <= threshold_health_date) & (deltas >= 0))\n",
    "\n",
    "    return healthevents\n",
    "\n",
    "\n",
    "def combine_with_other_datasets_single_cow(df_nsaiet, df_other, columns_both='idani_anon'):\n",
    "    \"\"\"\n",
    "    Function combining the dataframes hm_NSAIET and hm_milkrecording (already combined) with another dataframe\n",
    "    for a single cow ID.\n",
    "    \n",
    "    :param df_nsaiet: Subset of the NSAEIT Pandas dataframe containing all the relevant entries for a single cow\n",
    "    :param df_other: Subset of the other Pandas dataframe containing all the relevant entries for a single cow\n",
    "    :param columns_both: Identical columns in both dataframes\n",
    "    :return: Merged dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    combined_df = []\n",
    "    for idx_parity, parity_date in enumerate(df_nsaiet['nsaiet_date'].values):\n",
    "        df = pd.merge(df_nsaiet.iloc[[idx_parity]],\n",
    "                      df_other.iloc[[0]],\n",
    "                      \"inner\", on=columns_both)\n",
    "        combined_df.append(df)\n",
    "\n",
    "    return pd.concat(combined_df).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def return_single_cow_subset(df, cow_id, identifier_col='idani_anon'):\n",
    "    \"\"\"\n",
    "    For a given dataframe, return the subset of the dataframe for a given cow_id.\n",
    "    \n",
    "    :param df: Pandas dataframe\n",
    "    :param cow_id: ID of the cow, whose data is to be selected\n",
    "    :param identifier_col: Name of the column containing the ID\n",
    "    :return: Subset of Pandas dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    left = df[identifier_col].searchsorted(cow_id, 'left')\n",
    "    right = df[identifier_col].searchsorted(cow_id, 'right')\n",
    "    return df[left:right]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_cols = {#'hm_BCS': ['BCS_date'],\n",
    "                 'hm_lactation': ['calving_date'],\n",
    "                 'hm_NSAIET': ['nsaiet_date'],\n",
    "                 'hm_animal': ['birth_date'], \n",
    "                 'hm_milkrecording': ['mlksmpl_date', 'lab_date'],\n",
    "                 'hm_ebv': False,\n",
    "#                  'hm_pregnancy': ['pregnancy_detection_date'],\n",
    "                 'hm_health': ['healthevent_date']\n",
    "                 }\n",
    "\n",
    "fnames = list(datetime_cols.keys())\n",
    "\n",
    "fnames_wo_nsaiet_milkrec = [fname for fname in fnames if (fname != 'hm_NSAIET') and (fname != 'hm_milkrecording')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 341/180005 [00:52<7:37:04,  6.55it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a19f1f13fd8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Combine with hm_ebv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'hm_ebv'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mdfcomb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_with_other_datasets_single_cow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfcomb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_cow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_both\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Combine with hm_animal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-158eb7055a4f>\u001b[0m in \u001b[0;36mcombine_with_other_datasets_single_cow\u001b[0;34m(df_nsaiet, df_other, columns_both)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mcombined_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx_parity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparity_date\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_nsaiet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nsaiet_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         df = pd.merge(df_nsaiet.iloc[[idx_parity]],\n\u001b[0m\u001b[1;32m    102\u001b[0m                       \u001b[0mdf_other\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                       \"inner\", on=columns_both)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36miloc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \"\"\"\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"_iLocIndexer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_merged = []\n",
    "\n",
    "counter = 0\n",
    "bunchsize = 500\n",
    "\n",
    "for cow_id in tqdm.tqdm(unique_cow_ids[:nsamples]):\n",
    "    # Merge NSAIET & milkrecording\n",
    "    single_cow_nsaiet = return_single_cow_subset(data_frames['hm_NSAIET'], cow_id)\n",
    "    single_cow_milkrecording = return_single_cow_subset(data_frames['hm_milkrecording'], cow_id)\n",
    "    \n",
    "    dfcomb = combine_nsaeit_with_milkrecording_single_cow(single_cow_nsaiet, single_cow_milkrecording)\n",
    "    \n",
    "    # Skip Cow ID in case of an emtpy dataframe\n",
    "    if dfcomb is None:\n",
    "        continue\n",
    "    \n",
    "    for fname in fnames_wo_nsaiet_milkrec:\n",
    "        single_cow = return_single_cow_subset(data_frames[fname], cow_id)\n",
    "        col_both = list(set.intersection(set(dfcomb.keys().values), set(data_frames[fname].keys().values)))\n",
    "\n",
    "        # Combine with hm_lactation\n",
    "        if fname == 'hm_lactation':\n",
    "            dfcomb = combine_nsaeit_with_lactation_single_cow(dfcomb, single_cow, col_both)\n",
    "\n",
    "        # Combine with hm_ebv\n",
    "        if fname == 'hm_ebv':\n",
    "            dfcomb = combine_with_other_datasets_single_cow(dfcomb, single_cow, col_both)\n",
    "\n",
    "        # Combine with hm_animal\n",
    "        if fname == 'hm_animal':\n",
    "            dfcomb = combine_with_other_datasets_single_cow(dfcomb, single_cow, col_both)\n",
    "\n",
    "        # Combine with hm_health\n",
    "        if fname == 'hm_health':\n",
    "            dfcomb['healthevents'] = combine_with_health_single_cow(dfcomb, single_cow, threshold_health_date=45)\n",
    "            \n",
    "    # Append dataframes\n",
    "    df_merged.append(dfcomb)\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "    # Concatenate all dataframe and reset list after N=bunchsize samples\n",
    "    if counter == bunchsize:\n",
    "        df_merged_all = pd.concat(df_merged).reset_index(drop=True)\n",
    "        df_merged = []\n",
    "    elif counter % bunchsize == 0:\n",
    "        df_merged_all = df_merged_all.append(pd.concat(df_merged).reset_index(drop=True), ignore_index=True)\n",
    "        df_merged = []\n",
    "\n",
    "if counter < bunchsize:\n",
    "    df_merged_all = pd.concat(df_merged).reset_index(drop=True)\n",
    "elif len(df_merged) != 0:\n",
    "    df_merged_all = df_merged_all.append(pd.concat(df_merged).reset_index(drop=True), ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add columns with age and days since calving, drop datetime columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_merged_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9bfe3f044373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add columns (deltas between dates)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_merged_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_merged_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nsaiet_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_merged_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'birth_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_merged_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'days_since_calving'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_merged_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nsaiet_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_merged_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'calving_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_merged_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'days_since_mlksample'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_merged_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nsaiet_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_merged_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mlksmpl_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_merged_all' is not defined"
     ]
    }
   ],
   "source": [
    "# Add columns (deltas between dates)\n",
    "df_merged_all['age'] = (df_merged_all['nsaiet_date'] - df_merged_all['birth_date']).values // np.timedelta64(1, 'D')\n",
    "df_merged_all['days_since_calving'] = (df_merged_all['nsaiet_date'] - df_merged_all['calving_date']).values // np.timedelta64(1, 'D')\n",
    "df_merged_all['days_since_mlksample'] = (df_merged_all['nsaiet_date'] - df_merged_all['mlksmpl_date']).values // np.timedelta64(1, 'D')\n",
    "\n",
    "# # Drop columns with datetimes, since only the deltas are relevant\n",
    "# columns_to_drop = ['nsaiet_date', 'birth_date', 'calving_date', 'mlksmpl_date', 'lab_date', 'birth_date']\n",
    "# df_merged_all = df_merged_all.drop(labels=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_merged_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c2449f091956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_merged_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_merged_all' is not defined"
     ]
    }
   ],
   "source": [
    "df_merged_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data, create a dataset structure file for the AutoML platform, and tar the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_merged_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3479a503d9dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfolderpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfpath_prepared_data_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfoldername_prepared_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_merged_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolderpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_merged_all' is not defined"
     ]
    }
   ],
   "source": [
    "folderpath = fpath_prepared_data_dir + foldername_prepared_data\n",
    "df_merged_all.to_csv(folderpath+'data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataset structure file (DSSF), which is needed for the AutoML analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"name\": \"ai_basic_all\",\n",
      "        \"path\": \"data.csv\",\n",
      "        \"type\": \"table\"\n",
      "    },\n",
      "    {\n",
      "        \"_version\": \"0.1\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Content of DSSF\n",
    "dssf_string = ['[',\n",
    "               '    {',\n",
    "               '        \\\"name\\\": \\\"{}\\\",'.format(foldername_prepared_data[:-1]),\n",
    "               '        \\\"path\\\": \\\"data.csv\\\",',\n",
    "               '        \\\"type\\\": \\\"table\\\"',\n",
    "               '    },',\n",
    "               '    {',\n",
    "               '        \\\"_version\\\": \\\"0.1\\\"',\n",
    "               '    }',\n",
    "               ']'\n",
    "              ]\n",
    "\n",
    "print('\\n'.join(dssf_string))\n",
    "\n",
    "# Write DSSF\n",
    "text_file = open(folderpath+'dataset_structure.json', 'w')\n",
    "n = text_file.write('\\n'.join(dssf_string))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tarball of all the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -cf {fpath_prepared_data_dir}{foldername_prepared_data[:-1]}.tar -C {fpath_prepared_data_dir} {foldername_prepared_data[:-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a file for a regression task (predict optimal date for insemination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername_prepared_data = 'ai_basic_all_predict_date/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {fpath_prepared_data_dir}{foldername_prepared_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_merged_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3ba0dfe502ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Remove all non-successful inseminations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_merged_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parity_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_merged_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_merged_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfolderpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfpath_prepared_data_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfoldername_prepared_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_merged_all' is not defined"
     ]
    }
   ],
   "source": [
    "# Remove all non-successful inseminations\n",
    "mask = df_merged_all['parity_labels'].values == 0\n",
    "df_merged_subset = df_merged_all.drop(np.arange(mask.size)[mask], axis=0).reset_index(drop=True)\n",
    "\n",
    "folderpath = fpath_prepared_data_dir + foldername_prepared_data\n",
    "df_merged_subset.to_csv(folderpath+'data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"name\": \"ai_basic_all_predict_date\",\n",
      "        \"path\": \"data.csv\",\n",
      "        \"type\": \"table\"\n",
      "    },\n",
      "    {\n",
      "        \"_version\": \"0.1\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Content of DSSF\n",
    "dssf_string = ['[',\n",
    "               '    {',\n",
    "               '        \\\"name\\\": \\\"{}\\\",'.format(foldername_prepared_data[:-1]),\n",
    "               '        \\\"path\\\": \\\"data.csv\\\",',\n",
    "               '        \\\"type\\\": \\\"table\\\"',\n",
    "               '    },',\n",
    "               '    {',\n",
    "               '        \\\"_version\\\": \\\"0.1\\\"',\n",
    "               '    }',\n",
    "               ']'\n",
    "              ]\n",
    "\n",
    "print('\\n'.join(dssf_string))\n",
    "\n",
    "# Write DSSF\n",
    "text_file = open(folderpath+'dataset_structure.json', 'w')\n",
    "n = text_file.write('\\n'.join(dssf_string))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -cf {fpath_prepared_data_dir}{foldername_prepared_data[:-1]}.tar -C {fpath_prepared_data_dir} {foldername_prepared_data[:-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
